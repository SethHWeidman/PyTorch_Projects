{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Control Flow + Weight Sharing\n",
    "--------------------------------------\n",
    "\n",
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange\n",
    "model: a fully-connected ReLU network that on each forward pass randomly chooses\n",
    "a number between 1 and 4 and has that many hidden layers, reusing the same\n",
    "weights multiple times to compute the innermost hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 685.166748046875\n",
      "1 716.2672119140625\n",
      "2 669.1483154296875\n",
      "3 666.2140502929688\n",
      "4 649.7866821289062\n",
      "5 663.4417724609375\n",
      "6 662.125732421875\n",
      "7 515.1488037109375\n",
      "8 474.4584045410156\n",
      "9 418.6979675292969\n",
      "10 651.2013549804688\n",
      "11 604.246826171875\n",
      "12 273.0561828613281\n",
      "13 230.65745544433594\n",
      "14 642.33447265625\n",
      "15 654.3265991210938\n",
      "16 631.9901733398438\n",
      "17 623.1936645507812\n",
      "18 610.7982788085938\n",
      "19 95.9649658203125\n",
      "20 517.8375854492188\n",
      "21 564.3501586914062\n",
      "22 87.16880798339844\n",
      "23 446.4664611816406\n",
      "24 504.5140686035156\n",
      "25 379.14117431640625\n",
      "26 448.0452880859375\n",
      "27 412.2851257324219\n",
      "28 372.36846923828125\n",
      "29 248.2703399658203\n",
      "30 220.92465209960938\n",
      "31 281.49908447265625\n",
      "32 377.87957763671875\n",
      "33 336.4659423828125\n",
      "34 179.73191833496094\n",
      "35 243.58837890625\n",
      "36 117.1220703125\n",
      "37 194.98748779296875\n",
      "38 143.90576171875\n",
      "39 149.97337341308594\n",
      "40 217.8767852783203\n",
      "41 113.43510437011719\n",
      "42 109.23954010009766\n",
      "43 85.36133575439453\n",
      "44 288.4894714355469\n",
      "45 348.6808776855469\n",
      "46 207.8501739501953\n",
      "47 225.65953063964844\n",
      "48 116.79838562011719\n",
      "49 256.6073913574219\n",
      "50 119.47684478759766\n",
      "51 70.58709716796875\n",
      "52 58.39851379394531\n",
      "53 111.43065643310547\n",
      "54 137.46446228027344\n",
      "55 180.34132385253906\n",
      "56 150.54592895507812\n",
      "57 108.45811462402344\n",
      "58 108.75542449951172\n",
      "59 72.83521270751953\n",
      "60 104.24958038330078\n",
      "61 52.355735778808594\n",
      "62 96.68692016601562\n",
      "63 88.91238403320312\n",
      "64 116.99498748779297\n",
      "65 43.677696228027344\n",
      "66 45.310428619384766\n",
      "67 126.90807342529297\n",
      "68 40.396339416503906\n",
      "69 75.69645690917969\n",
      "70 78.03803253173828\n",
      "71 30.73961067199707\n",
      "72 29.21833038330078\n",
      "73 58.95334243774414\n",
      "74 49.126564025878906\n",
      "75 21.86265754699707\n",
      "76 41.034812927246094\n",
      "77 109.15501403808594\n",
      "78 22.223100662231445\n",
      "79 17.131404876708984\n",
      "80 17.374826431274414\n",
      "81 155.22964477539062\n",
      "82 78.55561065673828\n",
      "83 14.0419921875\n",
      "84 114.07395935058594\n",
      "85 109.96276092529297\n",
      "86 19.61063003540039\n",
      "87 87.49774932861328\n",
      "88 73.07615661621094\n",
      "89 10.095198631286621\n",
      "90 46.65618133544922\n",
      "91 51.69977569580078\n",
      "92 11.890962600708008\n",
      "93 49.89165496826172\n",
      "94 31.94661521911621\n",
      "95 29.746244430541992\n",
      "96 33.61684799194336\n",
      "97 46.442562103271484\n",
      "98 23.928403854370117\n",
      "99 14.174731254577637\n",
      "100 20.78708839416504\n",
      "101 35.057735443115234\n",
      "102 26.417240142822266\n",
      "103 7.494495868682861\n",
      "104 8.471431732177734\n",
      "105 42.259796142578125\n",
      "106 17.914432525634766\n",
      "107 9.45733642578125\n",
      "108 21.75714874267578\n",
      "109 9.236868858337402\n",
      "110 8.521210670471191\n",
      "111 6.183332920074463\n",
      "112 37.33931350708008\n",
      "113 15.918055534362793\n",
      "114 12.617744445800781\n",
      "115 28.07695770263672\n",
      "116 15.125173568725586\n",
      "117 17.82858657836914\n",
      "118 5.616778373718262\n",
      "119 20.052831649780273\n",
      "120 17.754850387573242\n",
      "121 5.28715181350708\n",
      "122 6.197269439697266\n",
      "123 23.426328659057617\n",
      "124 12.857643127441406\n",
      "125 6.807579517364502\n",
      "126 12.737595558166504\n",
      "127 4.956709384918213\n",
      "128 23.59125518798828\n",
      "129 14.015482902526855\n",
      "130 5.607433795928955\n",
      "131 5.686603546142578\n",
      "132 15.185312271118164\n",
      "133 19.891498565673828\n",
      "134 5.4679412841796875\n",
      "135 13.610687255859375\n",
      "136 4.380608081817627\n",
      "137 4.4280524253845215\n",
      "138 6.8406853675842285\n",
      "139 12.607722282409668\n",
      "140 7.615841388702393\n",
      "141 2.451442241668701\n",
      "142 8.186365127563477\n",
      "143 14.218241691589355\n",
      "144 8.058822631835938\n",
      "145 2.3566641807556152\n",
      "146 6.853071212768555\n",
      "147 3.9534215927124023\n",
      "148 5.404933452606201\n",
      "149 5.756003379821777\n",
      "150 5.840190410614014\n",
      "151 5.119932174682617\n",
      "152 2.6986184120178223\n",
      "153 2.596832752227783\n",
      "154 5.435613632202148\n",
      "155 2.9478769302368164\n",
      "156 5.865298271179199\n",
      "157 1.633546233177185\n",
      "158 3.06475567817688\n",
      "159 3.734757661819458\n",
      "160 6.039684772491455\n",
      "161 1.9344950914382935\n",
      "162 1.7160776853561401\n",
      "163 3.791064739227295\n",
      "164 3.40425968170166\n",
      "165 4.0157952308654785\n",
      "166 3.1551170349121094\n",
      "167 3.0246150493621826\n",
      "168 1.7957614660263062\n",
      "169 3.100135326385498\n",
      "170 2.576364040374756\n",
      "171 1.9317667484283447\n",
      "172 1.6150504350662231\n",
      "173 3.0380771160125732\n",
      "174 3.074370861053467\n",
      "175 2.1293399333953857\n",
      "176 1.701308012008667\n",
      "177 0.9647061824798584\n",
      "178 7.040337085723877\n",
      "179 2.3025505542755127\n",
      "180 3.655768871307373\n",
      "181 3.569819450378418\n",
      "182 2.601374864578247\n",
      "183 1.9891787767410278\n",
      "184 1.127885103225708\n",
      "185 0.8929152488708496\n",
      "186 2.090712308883667\n",
      "187 2.475018262863159\n",
      "188 1.0608381032943726\n",
      "189 1.5631643533706665\n",
      "190 1.079913854598999\n",
      "191 1.341149926185608\n",
      "192 1.2633779048919678\n",
      "193 6.268770217895508\n",
      "194 2.205454111099243\n",
      "195 1.6317636966705322\n",
      "196 4.561235427856445\n",
      "197 4.405329704284668\n",
      "198 1.0796784162521362\n",
      "199 2.719651699066162\n",
      "200 0.8129434585571289\n",
      "201 0.6675800681114197\n",
      "202 3.125046730041504\n",
      "203 1.7495743036270142\n",
      "204 2.5601911544799805\n",
      "205 1.6290929317474365\n",
      "206 2.419217348098755\n",
      "207 2.231618881225586\n",
      "208 1.9551681280136108\n",
      "209 1.0897494554519653\n",
      "210 1.8526290655136108\n",
      "211 0.6996809840202332\n",
      "212 1.7841695547103882\n",
      "213 0.4908570647239685\n",
      "214 4.659221172332764\n",
      "215 2.1676299571990967\n",
      "216 2.2815701961517334\n",
      "217 2.475294828414917\n",
      "218 5.895245552062988\n",
      "219 1.4799668788909912\n",
      "220 1.7079288959503174\n",
      "221 2.8694026470184326\n",
      "222 2.635589361190796\n",
      "223 1.7001601457595825\n",
      "224 0.7270196676254272\n",
      "225 1.7582694292068481\n",
      "226 1.8812450170516968\n",
      "227 1.6505447626113892\n",
      "228 3.897639513015747\n",
      "229 0.8833692669868469\n",
      "230 3.947354555130005\n",
      "231 0.660574197769165\n",
      "232 2.562129259109497\n",
      "233 1.602157711982727\n",
      "234 0.43658068776130676\n",
      "235 2.0048561096191406\n",
      "236 0.3703290820121765\n",
      "237 2.6239044666290283\n",
      "238 1.6790547370910645\n",
      "239 1.5701490640640259\n",
      "240 0.4557860791683197\n",
      "241 2.8380446434020996\n",
      "242 1.8646529912948608\n",
      "243 1.562158465385437\n",
      "244 1.6813604831695557\n",
      "245 0.4731324315071106\n",
      "246 0.4490254521369934\n",
      "247 2.082786798477173\n",
      "248 0.20254695415496826\n",
      "249 1.6868171691894531\n",
      "250 1.4702661037445068\n",
      "251 1.6529393196105957\n",
      "252 1.5222948789596558\n",
      "253 1.1363435983657837\n",
      "254 1.703896403312683\n",
      "255 0.6674661040306091\n",
      "256 0.5159448385238647\n",
      "257 1.3646212816238403\n",
      "258 2.84421443939209\n",
      "259 0.5721349120140076\n",
      "260 0.4886268079280853\n",
      "261 1.201553225517273\n",
      "262 1.1609693765640259\n",
      "263 0.25760403275489807\n",
      "264 0.2369115799665451\n",
      "265 0.24005195498466492\n",
      "266 0.22728972136974335\n",
      "267 0.8356532454490662\n",
      "268 1.9725675582885742\n",
      "269 1.4349143505096436\n",
      "270 1.8293668031692505\n",
      "271 0.7593588829040527\n",
      "272 1.3771661520004272\n",
      "273 1.249288558959961\n",
      "274 0.9830201268196106\n",
      "275 1.0227309465408325\n",
      "276 0.6336297988891602\n",
      "277 0.8146923780441284\n",
      "278 1.1447548866271973\n",
      "279 0.6020116209983826\n",
      "280 1.1782666444778442\n",
      "281 1.3354359865188599\n",
      "282 1.1164023876190186\n",
      "283 1.1314204931259155\n",
      "284 1.03648841381073\n",
      "285 0.8649012446403503\n",
      "286 0.8866361379623413\n",
      "287 0.8677828907966614\n",
      "288 0.8067980408668518\n",
      "289 0.6771191954612732\n",
      "290 0.5708093047142029\n",
      "291 1.1663198471069336\n",
      "292 1.419761061668396\n",
      "293 0.37811124324798584\n",
      "294 1.1519014835357666\n",
      "295 0.22836287319660187\n",
      "296 0.8286213278770447\n",
      "297 1.357438564300537\n",
      "298 1.0917377471923828\n",
      "299 0.9357770681381226\n",
      "300 0.18995928764343262\n",
      "301 1.4942210912704468\n",
      "302 1.234263300895691\n",
      "303 0.7654895782470703\n",
      "304 0.18419963121414185\n",
      "305 1.0379972457885742\n",
      "306 2.167154312133789\n",
      "307 1.0830258131027222\n",
      "308 0.9925942420959473\n",
      "309 0.3645704388618469\n",
      "310 0.3822057545185089\n",
      "311 2.4037024974823\n",
      "312 1.374408483505249\n",
      "313 0.2930624485015869\n",
      "314 0.684258222579956\n",
      "315 2.432935953140259\n",
      "316 2.1105525493621826\n",
      "317 0.48200398683547974\n",
      "318 1.2086756229400635\n",
      "319 0.8549357056617737\n",
      "320 0.1335059404373169\n",
      "321 0.20485301315784454\n",
      "322 1.890195369720459\n",
      "323 1.2304595708847046\n",
      "324 0.11440353095531464\n",
      "325 1.1745474338531494\n",
      "326 1.3994615077972412\n",
      "327 0.584823727607727\n",
      "328 0.8719457387924194\n",
      "329 0.14078722894191742\n",
      "330 0.8704735040664673\n",
      "331 1.199735164642334\n",
      "332 0.07318707555532455\n",
      "333 0.9489549994468689\n",
      "334 0.09864645451307297\n",
      "335 0.971550464630127\n",
      "336 0.8338727355003357\n",
      "337 1.0157358646392822\n",
      "338 0.7877143025398254\n",
      "339 0.48891937732696533\n",
      "340 0.4958404004573822\n",
      "341 0.6002150177955627\n",
      "342 0.5317475199699402\n",
      "343 0.22346386313438416\n",
      "344 0.4572482407093048\n",
      "345 0.2713356018066406\n",
      "346 0.3770450949668884\n",
      "347 0.32642775774002075\n",
      "348 0.6124255061149597\n",
      "349 0.2221580147743225\n",
      "350 0.23557956516742706\n",
      "351 1.1911009550094604\n",
      "352 0.20227110385894775\n",
      "353 0.48673591017723083\n",
      "354 0.43699419498443604\n",
      "355 0.9382706880569458\n",
      "356 0.8954548835754395\n",
      "357 0.7994012832641602\n",
      "358 0.48139968514442444\n",
      "359 0.6407921314239502\n",
      "360 0.582407534122467\n",
      "361 0.5119373798370361\n",
      "362 0.4471094608306885\n",
      "363 0.8471184372901917\n",
      "364 0.37813088297843933\n",
      "365 0.34652048349380493\n",
      "366 0.330011785030365\n",
      "367 0.8921839594841003\n",
      "368 0.28323811292648315\n",
      "369 0.32115572690963745\n",
      "370 1.028740644454956\n",
      "371 0.7510208487510681\n",
      "372 0.6980345845222473\n",
      "373 0.12931588292121887\n",
      "374 0.7391112446784973\n",
      "375 0.11841725558042526\n",
      "376 0.6860781908035278\n",
      "377 0.10965363681316376\n",
      "378 0.5543336272239685\n",
      "379 0.500807523727417\n",
      "380 0.4257664978504181\n",
      "381 0.7546551823616028\n",
      "382 0.16877733170986176\n",
      "383 0.3058926463127136\n",
      "384 0.6918188333511353\n",
      "385 0.6203180551528931\n",
      "386 0.7517075538635254\n",
      "387 0.5359846949577332\n",
      "388 0.39711692929267883\n",
      "389 0.7022758722305298\n",
      "390 0.6553904414176941\n",
      "391 0.5331920981407166\n",
      "392 0.5194687843322754\n",
      "393 0.48044267296791077\n",
      "394 0.4571725130081177\n",
      "395 0.48575907945632935\n",
      "396 0.15515877306461334\n",
      "397 0.4370535612106323\n",
      "398 0.4161650240421295\n",
      "399 0.3717576861381531\n",
      "400 0.12072969228029251\n",
      "401 0.3075985312461853\n",
      "402 0.2565193772315979\n",
      "403 0.8779311776161194\n",
      "404 0.5900179743766785\n",
      "405 0.2703154981136322\n",
      "406 0.0971541628241539\n",
      "407 0.08739672601222992\n",
      "408 0.7914139628410339\n",
      "409 0.06195250526070595\n",
      "410 0.05207400023937225\n",
      "411 0.3585367500782013\n",
      "412 0.5472385287284851\n",
      "413 0.5084043145179749\n",
      "414 0.45610517263412476\n",
      "415 0.08412047475576401\n",
      "416 0.7564883232116699\n",
      "417 0.3154182434082031\n",
      "418 0.5856672525405884\n",
      "419 0.4993631839752197\n",
      "420 0.17288732528686523\n",
      "421 0.1899992972612381\n",
      "422 1.0215693712234497\n",
      "423 0.3813009262084961\n",
      "424 0.12753917276859283\n",
      "425 0.1417388767004013\n",
      "426 0.1469193547964096\n",
      "427 0.7595070600509644\n",
      "428 0.5502032041549683\n",
      "429 0.32504016160964966\n",
      "430 0.5771070718765259\n",
      "431 0.956526517868042\n",
      "432 0.6193699836730957\n",
      "433 0.2694433331489563\n",
      "434 0.32288557291030884\n",
      "435 0.5108123421669006\n",
      "436 0.08263493329286575\n",
      "437 0.0850709080696106\n",
      "438 0.5470361709594727\n",
      "439 0.2662280201911926\n",
      "440 0.22661224007606506\n",
      "441 0.19326251745224\n",
      "442 0.1957656294107437\n",
      "443 1.1503357887268066\n",
      "444 0.13525183498859406\n",
      "445 0.365554541349411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446 0.045957356691360474\n",
      "447 0.9381728172302246\n",
      "448 0.3522927165031433\n",
      "449 0.64239901304245\n",
      "450 0.5884502530097961\n",
      "451 0.3817349374294281\n",
      "452 0.08661539107561111\n",
      "453 0.3979063630104065\n",
      "454 0.6674526333808899\n",
      "455 0.13075731694698334\n",
      "456 0.34571757912635803\n",
      "457 0.1751527488231659\n",
      "458 0.41949495673179626\n",
      "459 0.6893526315689087\n",
      "460 0.3510071039199829\n",
      "461 0.49145132303237915\n",
      "462 0.4775811433792114\n",
      "463 0.5453117489814758\n",
      "464 0.47334325313568115\n",
      "465 0.3833746314048767\n",
      "466 0.5152800679206848\n",
      "467 0.2873888909816742\n",
      "468 0.493534117937088\n",
      "469 0.08340216428041458\n",
      "470 0.5045223832130432\n",
      "471 0.08799059689044952\n",
      "472 0.0833733007311821\n",
      "473 0.0680755078792572\n",
      "474 0.4551537334918976\n",
      "475 0.507404088973999\n",
      "476 0.38691529631614685\n",
      "477 0.2923770546913147\n",
      "478 0.323481023311615\n",
      "479 0.5142210125923157\n",
      "480 0.2810901999473572\n",
      "481 0.08804640173912048\n",
      "482 0.2459821254014969\n",
      "483 0.23974791169166565\n",
      "484 0.44389182329177856\n",
      "485 0.17990386486053467\n",
      "486 0.1565612405538559\n",
      "487 0.545596182346344\n",
      "488 0.1389005333185196\n",
      "489 0.5190410017967224\n",
      "490 0.16400371491909027\n",
      "491 0.4513131082057953\n",
      "492 0.10426866263151169\n",
      "493 0.0821228176355362\n",
      "494 0.17031629383563995\n",
      "495 0.08112481981515884\n",
      "496 0.8266907334327698\n",
      "497 0.27882757782936096\n",
      "498 0.168723002076149\n",
      "499 0.4308582544326782\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
